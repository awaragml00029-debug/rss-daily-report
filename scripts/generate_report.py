#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RSS Daily Report Generator
ä» Google Sheets è¯»å– RSS æ•°æ®ï¼Œç”Ÿæˆæ¯æ—¥ Markdown æŠ¥å‘Š
"""

import os
import re
import sys
from datetime import datetime, timedelta
from collections import Counter
from typing import List, Dict, Any, Optional
import yaml
import gspread
from oauth2client.service_account import ServiceAccountCredentials


class RSSReportGenerator:
    """RSS æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.config = self._load_config(config_path)
        self.client = self._authenticate_google_sheets()
        self.sheet = None
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _authenticate_google_sheets(self) -> gspread.Client:
        """è®¤è¯ Google Sheets"""
        scope = [
            'https://spreadsheets.google.com/feeds',
            'https://www.googleapis.com/auth/drive'
        ]
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–å‡­è¯
        creds_json = os.getenv('GOOGLE_CREDENTIALS')
        if not creds_json:
            raise ValueError("æœªæ‰¾åˆ° GOOGLE_CREDENTIALS ç¯å¢ƒå˜é‡")
        
        # å°† JSON å­—ç¬¦ä¸²å†™å…¥ä¸´æ—¶æ–‡ä»¶
        import json
        creds_dict = json.loads(creds_json)
        
        credentials = ServiceAccountCredentials.from_json_keyfile_dict(
            creds_dict, scope
        )
        return gspread.authorize(credentials)
    
    def connect_sheet(self) -> gspread.Worksheet:
        """è¿æ¥åˆ°æŒ‡å®šçš„ Google Sheet"""
        spreadsheet_id = os.getenv('SHEET_ID') or self.config['google_sheets']['spreadsheet_id']
        sheet_name = self.config['google_sheets']['sheet_name']
        
        spreadsheet = self.client.open_by_key(spreadsheet_id)
        self.sheet = spreadsheet.worksheet(sheet_name)
        return self.sheet
    
    def get_all_data(self) -> List[List[str]]:
        """è·å–æ‰€æœ‰æ•°æ®"""
        if not self.sheet:
            self.connect_sheet()
        return self.sheet.get_all_values()
    
    def parse_datetime(self, date_str: str) -> Optional[datetime]:
        """è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²"""
        if not date_str:
            return None
        
        # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
        formats = [
            '%m/%d/%Y',           # 8/12/2025
            '%Y-%m-%d',           # 2025-08-12
            '%Y/%m/%d',           # 2025/08/12
            '%m/%d/%Y %H:%M',     # 8/12/2025 10:30
            '%Y-%m-%d %H:%M',     # 2025-08-12 10:30
            '%Y-%m-%d %H:%M:%S',  # 2025-08-12 10:30:45
        ]
        
        for fmt in formats:
            try:
                return datetime.strptime(date_str.strip(), fmt)
            except ValueError:
                continue
        
        # å¦‚æœéƒ½å¤±è´¥ï¼Œå°è¯•è§£ææ›´å¤æ‚çš„æ ¼å¼
        try:
            # å¤„ç†ç±»ä¼¼ "Mon, 11 Aug 2025 22:37:00 +0800" çš„æ ¼å¼
            from dateutil import parser
            return parser.parse(date_str)
        except:
            print(f"è­¦å‘Š: æ— æ³•è§£ææ—¥æœŸ '{date_str}'", file=sys.stderr)
            return None
    
    def filter_by_keywords(self, title: str) -> List[str]:
        """
        æ ¹æ®å…³é”®è¯ç­›é€‰ï¼Œè¿”å›åŒ¹é…çš„å…³é”®è¯åˆ—è¡¨
        æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
        """
        if not title:
            return []
        
        keywords = self.config.get('keywords', [])
        exclude_keywords = self.config.get('exclude_keywords', [])
        
        # æ£€æŸ¥æ’é™¤å…³é”®è¯
        for exclude_kw in exclude_keywords:
            if re.search(exclude_kw, title, re.IGNORECASE):
                return []
        
        # æ£€æŸ¥åŒ¹é…å…³é”®è¯
        matched = []
        for keyword in keywords:
            # å°†ç®€å•å…³é”®è¯è½¬æ¢ä¸ºæ­£åˆ™ï¼ˆæ”¯æŒä¸­é—´æ’å…¥å­—ç¬¦ï¼‰
            # ä¾‹å¦‚: "å•ç»†èƒ" -> "å•.*ç»†.*èƒ"
            pattern = '.*'.join(list(keyword))
            if re.search(pattern, title, re.IGNORECASE):
                matched.append(keyword)
        
        return matched
    
    def get_latest_crawl_date(self, data: List[List[str]]) -> Optional[datetime]:
        """è·å–æœ€æ–°çš„æŠ“å–æ—¥æœŸ"""
        col_idx = self.config['columns']['crawl_time'] - 1
        dates = []
        
        for row in data[1:]:  # è·³è¿‡è¡¨å¤´
            if len(row) > col_idx and row[col_idx]:
                dt = self.parse_datetime(row[col_idx])
                if dt:
                    dates.append(dt)
        
        return max(dates) if dates else None
    
    def filter_data_by_date(
        self, 
        data: List[List[str]], 
        target_date: datetime
    ) -> List[Dict[str, Any]]:
        """
        ç­›é€‰æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼Œå¹¶è¿›è¡Œå…³é”®è¯è¿‡æ»¤
        """
        col_map = self.config['columns']
        filtered_items = []
        
        for row in data[1:]:  # è·³è¿‡è¡¨å¤´
            if len(row) < 8:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                continue
            
            # è·å–æŠ“å–æ—¶é—´
            crawl_time_str = row[col_map['crawl_time'] - 1]
            crawl_time = self.parse_datetime(crawl_time_str)
            
            if not crawl_time:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡æ—¥æœŸï¼ˆåªæ¯”è¾ƒå¹´æœˆæ—¥ï¼‰
            if crawl_time.date() != target_date.date():
                continue
            
            # è·å–æ ‡é¢˜å¹¶è¿›è¡Œå…³é”®è¯åŒ¹é…
            title = row[col_map['title'] - 1]
            matched_keywords = self.filter_by_keywords(title)
            
            if not matched_keywords:  # æ²¡æœ‰åŒ¹é…çš„å…³é”®è¯ï¼Œè·³è¿‡
                continue
            
            # æ„å»ºæ•°æ®é¡¹
            item = {
                'crawl_time': crawl_time_str,
                'attribute': row[col_map['attribute'] - 1] if len(row) > col_map['attribute'] - 1 else '',
                'source_name': row[col_map['source_name'] - 1] if len(row) > col_map['source_name'] - 1 else '',
                'category': row[col_map['category'] - 1] if len(row) > col_map['category'] - 1 else '',
                'title': title,
                'link': row[col_map['link'] - 1] if len(row) > col_map['link'] - 1 else '',
                'publish_time': row[col_map['publish_time'] - 1] if len(row) > col_map['publish_time'] - 1 else '',
                'author': row[col_map['author'] - 1] if len(row) > col_map['author'] - 1 else '',
                'matched_keywords': matched_keywords,
            }
            filtered_items.append(item)
        
        return filtered_items
    
    def generate_daily_report(
        self, 
        items: List[Dict[str, Any]], 
        date: datetime
    ) -> str:
        """ç”Ÿæˆæ¯æ—¥ Markdown æŠ¥å‘Š"""
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_count = len(items)
        keyword_counter = Counter()
        for item in items:
            keyword_counter.update(item['matched_keywords'])
        
        # æŒ‰æŠ“å–æ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
        items.sort(
            key=lambda x: self.parse_datetime(x['crawl_time']) or datetime.min,
            reverse=True
        )
        
        # ç”Ÿæˆ Markdown
        md_lines = []
        md_lines.append(f"# ğŸ“… Daily Report - {date.strftime('%Y-%m-%d')}")
        md_lines.append("")
        md_lines.append("> ç”Ÿç‰©ä¿¡æ¯å­¦ RSS è®¢é˜…æ—¥æŠ¥")
        md_lines.append(f"> ç­›é€‰å…³é”®è¯ï¼š{', '.join(self.config['keywords'])}")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        md_lines.append("## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ")
        md_lines.append("")
        md_lines.append(f"- âœ… å‘½ä¸­æ¡ç›®ï¼š{total_count}")
        md_lines.append(f"- ğŸ“Œ å…³é”®è¯å‘½ä¸­ï¼š{sum(keyword_counter.values())} æ¬¡")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")
        
        # å†…å®¹åˆ—è¡¨
        md_lines.append("## ğŸ“° å†…å®¹åˆ—è¡¨")
        md_lines.append("")
        
        for idx, item in enumerate(items, 1):
            keywords_str = "ã€".join(item['matched_keywords'])
            md_lines.append(f"### {idx}. {item['title']}")
            md_lines.append("")
            md_lines.append(f"**åŒ¹é…å…³é”®è¯**ï¼š{keywords_str}  ")
            
            if item['source_name']:
                md_lines.append(f"**æ¥æº**ï¼š{item['source_name']}  ")
            
            if item['author']:
                md_lines.append(f"**ä½œè€…**ï¼š{item['author']}  ")
            
            if item['publish_time']:
                md_lines.append(f"**å‘å¸ƒæ—¶é—´**ï¼š{item['publish_time']}  ")
            
            if item['link']:
                md_lines.append(f"**é“¾æ¥**ï¼š[é˜…è¯»åŸæ–‡]({item['link']})")
            
            md_lines.append("")
            md_lines.append("---")
            md_lines.append("")
        
        # å…³é”®è¯ç»Ÿè®¡
        if keyword_counter:
            md_lines.append("## ğŸ·ï¸ å…³é”®è¯ç»Ÿè®¡")
            md_lines.append("")
            for keyword, count in keyword_counter.most_common():
                md_lines.append(f"- {keyword}ï¼š{count} æ¬¡")
            md_lines.append("")
        
        # é¡µè„š
        md_lines.append("---")
        md_lines.append("")
        md_lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}*")
        
        return "\n".join(md_lines)
    
    def generate_monthly_report(
        self,
        year: int,
        month: int
    ) -> str:
        """ç”Ÿæˆæœˆåº¦æŠ¥å‘Šï¼ˆæ±‡æ€»å½“æœˆæ‰€æœ‰æ—¥æŠ¥ï¼‰"""
        
        # è·å–å½“æœˆæ‰€æœ‰æ•°æ®
        all_data = self.get_all_data()
        
        # è·å–å½“æœˆæ‰€æœ‰æ—¥æœŸ
        month_start = datetime(year, month, 1)
        if month == 12:
            month_end = datetime(year + 1, 1, 1) - timedelta(days=1)
        else:
            month_end = datetime(year, month + 1, 1) - timedelta(days=1)
        
        # æ”¶é›†å½“æœˆæ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®
        all_items = []
        current_date = month_start
        while current_date <= month_end:
            daily_items = self.filter_data_by_date(all_data, current_date)
            all_items.extend(daily_items)
            current_date += timedelta(days=1)
        
        # ç»Ÿè®¡
        total_count = len(all_items)
        keyword_counter = Counter()
        for item in all_items:
            keyword_counter.update(item['matched_keywords'])
        
        # æŒ‰æ—¥æœŸåˆ†ç»„
        items_by_date = {}
        for item in all_items:
            crawl_time = self.parse_datetime(item['crawl_time'])
            if crawl_time:
                date_key = crawl_time.strftime('%Y-%m-%d')
                if date_key not in items_by_date:
                    items_by_date[date_key] = []
                items_by_date[date_key].append(item)
        
        # ç”ŸæˆæŠ¥å‘Š
        md_lines = []
        md_lines.append(f"# ğŸ“… Monthly Report - {year}å¹´{month}æœˆ")
        md_lines.append("")
        md_lines.append("> ç”Ÿç‰©ä¿¡æ¯å­¦ RSS è®¢é˜…æœˆæŠ¥")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")
        
        # æœˆåº¦ç»Ÿè®¡
        md_lines.append("## ğŸ“Š æœ¬æœˆæ¦‚è§ˆ")
        md_lines.append("")
        md_lines.append(f"- ğŸ“… ç»Ÿè®¡å‘¨æœŸï¼š{month_start.strftime('%Y-%m-%d')} è‡³ {month_end.strftime('%Y-%m-%d')}")
        md_lines.append(f"- âœ… æ€»å‘½ä¸­æ¡ç›®ï¼š{total_count}")
        md_lines.append(f"- ğŸ“† æ´»è·ƒå¤©æ•°ï¼š{len(items_by_date)}")
        md_lines.append(f"- ğŸ“ˆ æ—¥å‡æ¡ç›®ï¼š{total_count // len(items_by_date) if items_by_date else 0}")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")
        
        # å…³é”®è¯ç»Ÿè®¡
        md_lines.append("## ğŸ·ï¸ æœ¬æœˆå…³é”®è¯ç»Ÿè®¡")
        md_lines.append("")
        for keyword, count in keyword_counter.most_common():
            md_lines.append(f"- {keyword}ï¼š{count} æ¬¡")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")
        
        # æ¯æ—¥æ‘˜è¦
        md_lines.append("## ğŸ“† æ¯æ—¥æ‘˜è¦")
        md_lines.append("")
        
        for date_key in sorted(items_by_date.keys(), reverse=True):
            items = items_by_date[date_key]
            md_lines.append(f"### {date_key} ({len(items)} æ¡)")
            md_lines.append("")
            
            # åˆ—å‡ºè¯¥æ—¥çš„æ–‡ç« æ ‡é¢˜
            for item in items[:10]:  # æ¯å¤©æœ€å¤šæ˜¾ç¤º10æ¡
                keywords_str = "ã€".join(item['matched_keywords'])
                md_lines.append(f"- [{item['title']}]({item['link']}) *({keywords_str})*")
            
            if len(items) > 10:
                md_lines.append(f"- *...è¿˜æœ‰ {len(items) - 10} æ¡*")
            
            md_lines.append("")
        
        # é¡µè„š
        md_lines.append("---")
        md_lines.append("")
        md_lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}*")
        
        return "\n".join(md_lines)
    
    def save_report(self, content: str, filepath: str):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {filepath}")
    
    def run_daily(self, target_date: Optional[datetime] = None):
        """è¿è¡Œæ¯æ—¥æŠ¥å‘Šç”Ÿæˆ"""
        print("ğŸš€ å¼€å§‹ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š...")
        
        # è·å–æ•°æ®
        all_data = self.get_all_data()
        print(f"ğŸ“Š å…±è¯»å– {len(all_data) - 1} è¡Œæ•°æ®")
        
        # ç¡®å®šç›®æ ‡æ—¥æœŸ
        if not target_date:
            latest_date = self.get_latest_crawl_date(all_data)
            if not latest_date:
                print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„æŠ“å–æ—¥æœŸ")
                return
            target_date = latest_date
        
        print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {target_date.strftime('%Y-%m-%d')}")
        
        # ç­›é€‰æ•°æ®
        filtered_items = self.filter_data_by_date(all_data, target_date)
        print(f"âœ… ç­›é€‰å‡º {len(filtered_items)} æ¡ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
        
        if not filtered_items:
            print("âš ï¸  æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®ï¼Œè·³è¿‡æŠ¥å‘Šç”Ÿæˆ")
            return
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = self.generate_daily_report(filtered_items, target_date)
        
        # ä¿å­˜æŠ¥å‘Š
        output_config = self.config['output']
        filepath = os.path.join(
            output_config['daily_path'].format(
                year=target_date.year,
                month=f"{target_date.month:02d}"
            ),
            output_config['daily_filename'].format(
                date=target_date.strftime('%Y-%m-%d')
            )
        )
        
        self.save_report(report_content, filepath)
        print("âœ¨ æ¯æ—¥æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    
    def run_monthly(self, year: Optional[int] = None, month: Optional[int] = None):
        """è¿è¡Œæœˆåº¦æŠ¥å‘Šç”Ÿæˆ"""
        print("ğŸš€ å¼€å§‹ç”Ÿæˆæœˆåº¦æŠ¥å‘Š...")
        
        # ç¡®å®šå¹´æœˆ
        now = datetime.now()
        if not year:
            year = now.year
        if not month:
            month = now.month
        
        print(f"ğŸ“… ç›®æ ‡æœˆä»½: {year}å¹´{month}æœˆ")
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = self.generate_monthly_report(year, month)
        
        # ä¿å­˜æŠ¥å‘Š
        output_config = self.config['output']
        filepath = os.path.join(
            output_config['monthly_path'].format(year=year),
            output_config['monthly_filename'].format(
                year=year,
                month=f"{month:02d}"
            )
        )
        
        self.save_report(report_content, filepath)
        print("âœ¨ æœˆåº¦æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='RSS Daily Report Generator')
    parser.add_argument(
        '--mode',
        choices=['daily', 'monthly'],
        default='daily',
        help='ç”Ÿæˆæ¨¡å¼ï¼šdailyï¼ˆæ¯æ—¥ï¼‰æˆ– monthlyï¼ˆæ¯æœˆï¼‰'
    )
    parser.add_argument(
        '--date',
        help='æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)ï¼Œä»…ç”¨äº daily æ¨¡å¼'
    )
    parser.add_argument(
        '--year',
        type=int,
        help='æŒ‡å®šå¹´ä»½ï¼Œä»…ç”¨äº monthly æ¨¡å¼'
    )
    parser.add_argument(
        '--month',
        type=int,
        help='æŒ‡å®šæœˆä»½ï¼Œä»…ç”¨äº monthly æ¨¡å¼'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = RSSReportGenerator()
    
    try:
        if args.mode == 'daily':
            # æ¯æ—¥æŠ¥å‘Š
            target_date = None
            if args.date:
                target_date = datetime.strptime(args.date, '%Y-%m-%d')
            generator.run_daily(target_date)
            
        elif args.mode == 'monthly':
            # æœˆåº¦æŠ¥å‘Š
            generator.run_monthly(args.year, args.month)
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
